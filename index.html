<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Tanuj Sur</title>

    <meta name="author" content="Tanuj Sur">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Tanuj Sur
                </p>
                <p>I'm a Data Scientist at <a href="https://in.micron.com/">Micron Technology</a> in Hyderabad, India, where I work mostly on problems at the intersection of semiconductor industry and AI.
                </p>
                <p>
                  I did my MSc. in Data Science from <a href="https://www.cmi.ac.in/">Chennai Mathematical Institute</a> and my BSc. in Statistics from <a href="https://www.sxccal.edu/">St. Xavier's College (Autonomous), Kolkata</a> (under Calcutta University).
                </p>
                <p style="text-align:center">
                  <a href="mailto:surtantheta@gmail.com">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="data/TanujSur-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=S93m1WoAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/surtantheta/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/TanujSur.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 70%;" alt="profile photo" src="images/TanujSur.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision problems related to egocentric vision, video understanding, 3D reconstruction and scene understanding. My research till now has been primarily in meta learning, incremental learning and data efficient learning. My research works have been highlighted below.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='wacv_image'>
					  <img src='images/wacv_after.jpg' width=100%>
					</div>
          <img src='images/wacv_before.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('wacv_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('wacv_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <!-- <a href="https://ever.github.io/"> -->
			<span class="papertitle">Hyperbolic Uncertainty‑Aware Few‑Shot Incremental Point Cloud Segmentation
</span>
        </a>
        <br>
				<strong>Tanuj Sur</strong>,
        <a href="https://scholar.google.com/citations?user=zHF9tloAAAAJ&hl=en">Samrat Mukherjee</a>,
        <a href="https://openreview.net/profile?id=~Kaizer_Rahaman1">Kaizer Rahman</a>,
        <a href="https://www.ee.iitb.ac.in/~sc/">Dr. Subhasis Chaudhury</a>,
        <a href="https://biplab-banerjee.github.io/">Dr. Biplab Banerjee</a>
				<br>
        <em>Under review at WACV</em>, 2025
        <!-- <br> -->
        <!-- <a href="https://half-potato.gitlab.io/posts/ever/">project page</a> -->
        <!-- / -->
        <!-- <a href="https://arxiv.org/abs/2410.01804">arXiv</a> -->
        <p></p>
        <p>
        In real-world applications, 3D point cloud recognition and segmentation are crucial for tasks such as scene understanding and motion planning in autonomous driving and robotics. Traditional segmentation methods often struggle to adapt to dynamic environments or novel categories with limited prior knowledge, necessitating the integration of few-shot learning and class incremental learning paradigms into 3D point cloud segmentation. While existing approaches exist for Few-Shot learning and Class Incremental learning for 3D point cloud segmentation, there remains a significant gap in the literature specifically addressing Few-Shot Class Incremental Learning (FSCIL) tailored for 3D point cloud segmentation.
        </p>
      </td>
    </tr>

  <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
        <source src="images/dreamfusion.mp4" type="video/mp4">
        Your browser does not support the video tag.
        </video></div>
        <img src='images/dreamfusion.jpg' width="160">
      </div>
      <script type="text/javascript">
        function dreamfusion_start() {
          document.getElementById('dreamfusion_image').style.opacity = "1";
        }

        function dreamfusion_stop() {
          document.getElementById('dreamfusion_image').style.opacity = "0";
        }
        dreamfusion_stop()
      </script>
    </td>
    
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1zFzCaFwkGK1EGmJ_KEqb-ZsRJhfUKN2S/view?usp=sharing">
                  <span class="papertitle">The Fast Bilateral Solver</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>,
                <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>
                <br>
                <em>ECCV</em>, 2016 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Honorable Mention)</strong></font>
                <br>
                <a href="http://arxiv.org/abs/1511.03296">arXiv</a> /
                <a href="data/BarronPooleECCV2016.bib">bibtex</a> /
                <a href="http://videolectures.net/eccv2016_barron_bilateral_solver/">video (they messed up my slides, use &rarr;)</a> /
                <a href="https://drive.google.com/file/d/19x1AeN0PFus6Pjrd8nR-vCmJ6bNEefsC/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/1p9nduiymK9jUh7WfwlsMjBfW8RoNe_61/view?usp=sharing">PDF</a>) /
                <a href="https://github.com/poolio/bilateral_solver">code</a> /
                <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmaDI3bm5VeDRxams/view?usp=sharing&resourcekey=0-pmkbnOuy8caA7-3GGSfeNQ">depth super-res results</a> /
                <a href="data/BarronPooleECCV2016_reviews.txt">reviews</a>
                <p></p>
                <p>Our solver smooths things better than other filters and faster than other optimization algorithms, and you can backprop through it.</p>
              </td>
            </tr>

            <tr onmouseout="diverdi_stop()" onmouseover="diverdi_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='diverdi_image'><img src='images/diverdi_after.jpg'></div>
                  <img src='images/diverdi_before.jpg'>
                </div>
                <script type="text/javascript">
                  function diverdi_start() {
                    document.getElementById('diverdi_image').style.opacity = "1";
                  }

                  function diverdi_stop() {
                    document.getElementById('diverdi_image').style.opacity = "0";
                  }
                  diverdi_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1mmT-LuK_eBZsl3qp4-fAshEPdgfbgvNE/view?usp=sharing">
                  <span class="papertitle">Geometric Calibration for Mobile, Stereo, Autofocus Cameras</span>
                </a>
                <br>
                <a href="http://www.stephendiverdi.com/">Stephen DiVerdi</a>,
                <strong>Jonathan T. Barron</strong>
                <br>
                <em>WACV</em>, 2016
                <br>
                <a href="data/Diverdi2016.bib">bibtex</a>
                <p></p>
                <p>Standard techniques for stereo calibration don't work for cheap mobile cameras.</p>
              </td>
            </tr>

            <tr onmouseout="dt_stop()" onmouseover="dt_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dt_image'><img src='images/DT_edge.jpg'></div>
                  <img src='images/DT_image.jpg'>
                </div>
                <script type="text/javascript">
                  function dt_start() {
                    document.getElementById('dt_image').style.opacity = "1";
                  }

                  function dt_stop() {
                    document.getElementById('dt_image').style.opacity = "0";
                  }
                  dt_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/178Xj2PZ1w6hZJpucU-TiZOoCemJmvsVQ/view?usp=sharing">
                  <span class="papertitle">Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform</span>
                </a>
                <br>
                <em>CVPR</em>, 2016
                <br>
                <a href="http://liangchiehchen.com/">Liang-Chieh Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="http://ttic.uchicago.edu/~gpapan/">George Papandreou</a>, <a href="http://www.cs.ubc.ca/~murphyk/">Kevin Murphy</a>, <a href="http://www.stat.ucla.edu/~yuille/">Alan L. Yuille</a>
                <br>
                <a href="data/Chen2016.bib">bibtex</a> /
                <a href="http://liangchiehchen.com/projects/DeepLab.html">project page</a> /
                <a href="https://bitbucket.org/aquariusjay/deeplab-public-ver2">code</a>
                <p></p>
                <p>By integrating an edge-aware filter into a convolutional neural network we can learn an edge-detector while improving semantic segmentation.</p>
              </td>
            </tr>

            <tr onmouseout="ccc_stop()" onmouseover="ccc_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='ccc_image'><img src='images/ccc_after.jpg'></div>
                  <img src='images/ccc_before.jpg'>
                </div>
                <script type="text/javascript">
                  function ccc_start() {
                    document.getElementById('ccc_image').style.opacity = "1";
                  }

                  function ccc_stop() {
                    document.getElementById('ccc_image').style.opacity = "0";
                  }
                  ccc_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1id74VNDL8ACrrWf6vYgN2M4kS8gd4n7w/view?usp=sharing">
                  <span class="papertitle">Convolutional Color Constancy</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>
                <br>
                <em>ICCV</em>, 2015
                <br>
                <a href="https://drive.google.com/file/d/1vO3sVOMihmpNqsuASeR46Y_iME0lOANR/view?usp=sharing">supplement</a> / <a href="data/BarronICCV2015.bib">bibtex</a> / <a href="https://youtu.be/saHwKY9rfx0">video</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmalBNUzlENUJSVDg/view?usp=sharing">mp4</a>)
                <p></p>
                <p>By framing white balance as a chroma localization task we can discriminatively learn a color constancy model that beats the state-of-the-art by 40%.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/Shelhamer2015.jpg'>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1stygV71uBruD7Ck9CaAQr7nREvr3DtUL/view?usp=sharing">
                  <span class="papertitle">Scene Intrinsics and Depth from a Single Image</span>
                </a>
                <br>
                <a href="http://imaginarynumber.net/">Evan Shelhamer</a>, <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
                <br>
                <em>ICCV Workshop</em>, 2015
                <br>
                <a href="data/Shelhamer2015.bib">bibtex</a>
                <p></p>
                <p>The monocular depth estimates produced by fully convolutional networks can be used to inform intrinsic image estimation.</p>
              </td>
            </tr>

            <tr bgcolor="#ffffd0" onmouseout="defocus_stop()" onmouseover="defocus_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='lens_blurry' class='hidden'><img src="images/BarronCVPR2015_anim.gif"></div>
                <div id='lens_sharp'>
                  <a href="images/BarronCVPR2015_anim.gif"><img src="images/BarronCVPR2015_still.jpg"></a>
                </div>
                <script type="text/javascript">
                  function defocus_start() {
                    document.getElementById('lens_blurry').style.display = 'inline';
                    document.getElementById('lens_sharp').style.display = 'none';
                  }

                  function defocus_stop() {
                    document.getElementById('lens_blurry').style.display = 'none';
                    document.getElementById('lens_sharp').style.display = 'inline';
                  }
                  defocus_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1R4RdaBZIs-uJobhIFs9yKf3jIsaHQNH0/view?usp=sharing">
                  <span class="papertitle">Fast Bilateral-Space Stereo for Synthetic Defocus</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://people.csail.mit.edu/abadams/">Andrew Adams</a>, <a href="http://people.csail.mit.edu/yichangshih/">YiChang Shih</a>, <a href="http://carlos-hernandez.org/">Carlos Hern&aacutendez</a>
                <br>
                <em>CVPR</em>, 2015 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://drive.google.com/file/d/125qgMdqeT1vojMIijIKcOF099LjUgUOL/view?usp=sharing">abstract</a> /
                <a href="https://drive.google.com/file/d/1HGGvVOGxmPjvgdK5q3UD1Qb5Nttg6kq9/view?usp=sharing">supplement</a> /
                <a href="data/BarronCVPR2015.bib">bibtex</a> /
                <a href="http://techtalks.tv/talks/fast-bilateral-space-stereo-for-synthetic-defocus/61624/">talk</a> /
                <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSzZZdUJSMllSUkE/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/open?id=0B4nuwEMaEsnmZ1ZXUzBCWDJYeFU">PDF</a>)
                <p></p>
                <p>By embedding a stereo optimization problem in "bilateral-space" we can very quickly solve for an edge-aware depth map, letting us render beautiful depth-of-field effects.</p>
                <p>This technology is used by the <a href="http://googleresearch.blogspot.com/2014/04/lens-blur-in-new-google-camera-app.html">Google Camera "Lens Blur"</a> feature. </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/PABMM2015.jpg" alt="PontTuset" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/1503.00848" id="MCG_journal">
                  <span class="papertitle">Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation</span>
                </a>
                <br>
                <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>TPAMI</em>, 2017
                <br>
                <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
                <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a>
                <p></p>
                <p>We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.</p>
                <p>This paper subsumes our CVPR 2014 paper.</p>
              </td>
            </tr>

            <tr bgcolor="#ffffd0" onmouseout="sirfs_stop()" onmouseover="sirfs_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='sirfs_image'>
                    <a href="images/Estee.png"><img src='images/Estee_160.png' style="border-style: none"></a>
                  </div>
                  <a href="images/Estee.png"><img src='images/Estee_160_prodB2.png' style="border-style: none"></a>
                </div>
                <script type="text/javascript">
                  function sirfs_start() {
                    document.getElementById('sirfs_image').style.opacity = "1";
                  }

                  function sirfs_stop() {
                    document.getElementById('sirfs_image').style.opacity = "0";
                  }
                  sirfs_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <p>
                  <a href="https://arxiv.org/abs/2010.03592" id="SIRFS">
                    <span class="papertitle">Shape, Illumination, and Reflectance from Shading</span>
                  </a>
                  <br>
                  <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                  <br>
                  <em>TPAMI</em>, 2015
                  <br>
                  <a href="data/BarronMalikTPAMI2015.bib">bibtex</a> / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmVWpfa19mbUxIYW8/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmazJvLXJUb0NuM1U/view?usp=sharing">powerpoint</a>, <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmTDBUWE96VHJndjg/view?usp=sharing">PDF</a>) / <a href="http://www.youtube.com/watch?v=NnePYprvFvA">video</a> / <a href="https://drive.google.com/file/d/1vg9Rb-kBntSTnTCzVgFlskkPXvTB_5aq/view?usp=sharing">code &amp; data</a> / <a href="https://drive.google.com/file/d/11X5Zfjy7Q7oP_V2rtqy2f5-x9YgQUAFd/view?usp=sharing">kudos</a>
                </p>
                <p>
                  We present <strong>SIRFS</strong>, which can estimate shape, chromatic illumination, reflectance, and shading from a single image of an masked object.
                </p>
                <p>
                  This paper subsumes our CVPR 2011, CVPR 2012, and ECCV 2012 papers.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/ArbalaezCVPR2014.jpg" alt="ArbalaezCVPR2014" width="160" height="120" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1M0wijHY134F9ETBgO8mjeuKUSblTRLG0/view?usp=sharing">
                  <span class="papertitle">Multiscale Combinatorial Grouping</span>
                </a>
                <br>
                <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2014
                <br>
                <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
                <a href="data/ArbelaezCVPR2014.bib">bibtex</a>
                <p>This paper is subsumed by <a href="#MCG_journal">our journal paper</a>.</p>
              </td>
            </tr>

            <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='flyspin' class='hidden'><img src="images/BarronICCV2013_160.gif"></div>
                <div id='flystill'>
                  <a href="images/BarronICCV2013.gif"><img src="images/BarronICCV2013_160.jpg"></a>
                </div>
                <script type="text/javascript">
                  function flyspin_start() {
                    document.getElementById('flyspin').style.display = 'inline';
                    document.getElementById('flystill').style.display = 'none';
                  }

                  function flyspin_stop() {
                    document.getElementById('flyspin').style.display = 'none';
                    document.getElementById('flystill').style.display = 'inline';
                  }
                  flyspin_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1shvItvx_8Sb8QNXhrOXkuRmx2618iwNJ/view?usp=sharing">
                  <span class="papertitle">Volumetric Semantic Segmentation using Pyramid Context Features</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://big.lbl.gov/">Soile V. E. Ker&aumlnen</a>, <a href="http://www.lbl.gov/gsd/biggin.html">Mark D. Biggin</a>,
                <br> <a href="http://dwknowles.lbl.gov/">David W. Knowles</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>ICCV</em>, 2013
                <br>
                <a href="https://drive.google.com/file/d/1htiLpMAcYLtuBthmAb4XHnOYxUbkfnqR/view?usp=sharing">supplement</a> /
                <a href="https://drive.google.com/file/d/1qoYeFNa443myn2SfcdhmCsYBqE9xQrPD/view?usp=sharing">poster</a> /
                <a href="data/BarronICCV2013.bib">bibtex</a> / <a href="http://www.youtube.com/watch?v=Y56-FcfnlVA&hd=1">video 1</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="http://www.youtube.com/watch?v=mvRoYuP6-l4&hd=1">video 2</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSF9YdWJjQmh4QW8/view?usp=sharing">code &amp; data</a>
                <p>
                  We present a technique for efficient per-voxel linear classification, which enables accurate and fast semantic segmentation of volumetric Drosophila imagery.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/3DSP_160.jpg" alt="3DSP" width="160" height="120" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmbG1tOGIta3N1Wjg/view?usp=sharing" id="3DSP">
                  <span class="papertitle">3D Self-Portraits</span>
                </a>
                <br>
                <a href="http://www.hao-li.com/">Hao Li</a>, <a href="http://www.evouga.com/">Etienne Vouga</a>, Anton Gudym, <a href="http://www.cs.princeton.edu/~linjiel/">Linjie Luo</a>, <strong>Jonathan T. Barron</strong>, Gleb Gusev
                <br>
                <em>SIGGRAPH Asia</em>, 2013
                <br>
                <a href="http://www.youtube.com/watch?v=DmUkbZ0QMCA">video</a> / <a href="http://shapify.me/">shapify.me</a> / <a href="data/3DSP_siggraphAsia2013.bib">bibtex</a>
                <p>Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D sensor.</p>
              </td>
            </tr>

            <tr onmouseout="rgbd_stop()" onmouseover="rgbd_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='rgbd_anim' class='hidden'><img src="images/SceneSIRFS.gif"></div>
                <div id='rgbd_still'><img src="images/SceneSIRFS-still.jpg"></div>
                <script type="text/javascript">
                  function rgbd_start() {
                    document.getElementById('rgbd_anim').style.display = 'inline';
                    document.getElementById('rgbd_still').style.display = 'none';
                  }

                  function rgbd_stop() {
                    document.getElementById('rgbd_anim').style.display = 'none';
                    document.getElementById('rgbd_still').style.display = 'inline';
                  }
                  rgbd_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1snypSLhzC0jXCchJRsWpcDZ7Es5hDmXo/view?usp=sharing">
                  <span class="papertitle">Intrinsic Scene Properties from a Single RGB-D Image</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2013 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://drive.google.com/file/d/1cLUw72WpgdZ_3TQAjJABdgywqjBfn_Mq/view?usp=sharing">supplement</a> / <a href="data/BarronMalikCVPR2013.bib">bibtex</a> / <a href="http://techtalks.tv/talks/intrinsic-scene-properties-from-a-single-rgb-d-image/58614/">talk</a> / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmWW1CZGJPbi12R0k/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/19q3EFf6GIb4UFcCN2DVU2jVKpxRj5kxf/view?usp=sharing">powerpoint</a>, <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmMzQ4ZVp1SWdnVkk/view?usp=sharing">PDF</a>) / <a href="https://drive.google.com/open?id=1ZbPScVA6Efqd-ESvojl92sw8K-82Xxry">code &amp; data</a>
                <p>By embedding mixtures of shapes &amp; lights into a soft segmentation of an image, and by leveraging the output of the Kinect, we can extend SIRFS to scenes.
                  <br>
                  <br>TPAMI Journal version: <a href="https://drive.google.com/file/d/1iQiUxZvjPPnb8rFCwXYesTgFSRk7mkAq/view?usp=sharing">version</a> / <a href="data/BarronMalikTPAMI2015B.bib">bibtex</a>
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Boundary.jpg" alt="Boundary_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1H4YPovfrvcce3HGMEhidwU2l2fTcNR5y/view?usp=sharing">
                  <span class="papertitle">Boundary Cues for 3D Object Shape Recovery</span>
                </a>
                <br>
                <a href="http://www.kevinkarsch.com/">Kevin Karsch</a>,
                <a href="http://web.engr.illinois.edu/~liao17/">Zicheng Liao</a>,
                <a href="http://web.engr.illinois.edu/~jjrock2/">Jason Rock</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="http://www.cs.illinois.edu/homes/dhoiem/">Derek Hoiem</a>
                <br>
                <em>CVPR</em>, 2013
                <br>
                <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmLUQ5SVJTcUZIYXc/view?usp=sharing">supplement</a> / <a href="data/KarschCVPR2013.bib">bibtex</a>
                <p>Boundary cues (like occlusions and folds) can be used for shape reconstruction, which improves object recognition for humans and computers.</p>
              </td>
            </tr>

            <tr onmouseout="eccv12_stop()" onmouseover="eccv12_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='eccv12_anim' class='hidden'>
                  <a href="https://drive.google.com/file/d/1brxb58CfRPe7KEER4Q_fYS9B_J-hiS0t/view?usp=sharing"><img src="images/ECCV2012_small.gif"></a>
                </div>
                <div id='eccv12_still'><img src="images/ECCV2012_still.jpg"></div>
                <script type="text/javascript">
                  function eccv12_start() {
                    document.getElementById('eccv12_anim').style.display = 'inline';
                    document.getElementById('eccv12_still').style.display = 'none';
                  }

                  function eccv12_stop() {
                    document.getElementById('eccv12_anim').style.display = 'none';
                    document.getElementById('eccv12_still').style.display = 'inline';
                  }
                  eccv12_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1NczR4pJ-s0YBjCe0rCevMt8IM5JPuUrc/view?usp=sharing">
                  <span class="papertitle">Color Constancy, Intrinsic Images, and Shape Estimation</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>ECCV</em>, 2012
                <br>
                <a href="https://drive.google.com/file/d/1zuxhWZ3i6THvuRRBeE7dM_BJfDxO72Fq/view?usp=sharing">supplement</a> /
                <a href="data/BarronMalikECCV2012.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/12x8mhqpFsA6p0u6ZQW-ieRKF8hlQBKKe/view?usp=sharing">poster</a> /
                <a href="http://www.youtube.com/watch?v=NnePYprvFvA">video</a>
                <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
              </td>
            </tr>

            <tr onmouseout="cvpr12_stop()" onmouseover="cvpr12_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" style="height: 120px">
                  <div class="two" id='cvpr12_image' style="height: 120px">
                    <img src='images/BarronCVPR2012_after.jpg' style="border-style: none">
                  </div>
                  <img src='images/BarronCVPR2012_before.jpg' style="border-style: none">
                </div>
                <script type="text/javascript">
                  function cvpr12_start() {
                    document.getElementById('cvpr12_image').style.opacity = "1";
                  }

                  function cvpr12_stop() {
                    document.getElementById('cvpr12_image').style.opacity = "0";
                  }
                  cvpr12_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/17RfINbE2dr2EjXp9MtGO0MHJLQmQVhvT/view?usp=sharing">
                  <span class="papertitle">Shape, Albedo, and Illumination from a Single Image of an Unknown Object</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2012
                <br>
                <a href="https://drive.google.com/file/d/1Im_bUI42AP9VPoNtsjLajvtLRiwv39k3/view?usp=sharing">supplement</a> /
                <a href="data/BarronMalikCVPR2012.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/1IAlSF4k3_CEL9dfbaMiNTFPBoEkLhsRl/view?usp=sharing">poster</a>
                <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                  <span class="papertitle">A Category-Level 3-D Object Dataset: Putting the Kinect to Work</span>
                </a>
                <br>
                <a href="http://www.eecs.berkeley.edu/%7Eallie/">Allison Janoch</a>,
                <a href="http://sergeykarayev.com/">Sergey Karayev</a>,
                <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Yangqing Jia</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="http://www.cs.berkeley.edu/%7Emfritz/">Mario Fritz</a>,
                <a href="http://www.icsi.berkeley.edu/%7Esaenko/">Kate Saenko</a>,
                <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
                <br>
                <em>ICCV 3DRR Workshop</em>, 2011
                <br>
                <a href="data/B3DO_ICCV_2011.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>
                <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/safs.jpg" alt="safs_small" width="160" height="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1EZTOO5xezLYcyIFgAzs4KuZFLbTcwTDH/view?usp=sharing">
                  <span class="papertitle">High-Frequency Shape and Albedo from Shading using Natural Image Statistics</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2011
                <br>
                <a href="data/BarronMalikCVPR2011.bib">bibtex</a>
                <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/fast_texture.jpg" alt="fast-texture" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1rc05NatkQVmUDlGCAYcHSrvAzTpU9knT/view?usp=sharing">
                  <span class="papertitle">Discovering Efficiency in Coarse-To-Fine Texture Classification</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>Technical Report</em>, 2010
                <br>
                <a href="data/BarronTR2010.bib">bibtex</a>
                <p>A model and feature representation that allows for sub-linear coarse-to-fine semantic segmentation.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/prl.jpg" alt="prl" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
                  <span class="papertitle">Parallelizing Reinforcement Learning</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>
                <br>
                <em>Technical Report</em>, 2009
                <br>
                <a href="data/BarronPRL2009.bib">bibtex</a>
                <p>Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                  <span class="papertitle">Blind Date: Using Proper Motions to Determine the Ages of Historical Images</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 136, 2008
                <p>Using the relative motions of stars we can accurately estimate the date of origin of historical astronomical images.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                  <span class="papertitle">Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 135, 2008
                <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
                <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>
              </td>
            </tr>

          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cs188.jpg" alt="cs188">
              </td>
              <td width="75%" valign="center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
            
  </body>
</html>
